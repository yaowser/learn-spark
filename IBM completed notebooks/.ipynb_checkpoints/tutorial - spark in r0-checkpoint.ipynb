{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Spark in R\n",
    "This notebook is designed to introduce some basic concepts and help get you familiar with using Spark in R. If you want to learn more, see the resources at the bottom of this notebook.  \n",
    "\n",
    "In this notebook, we will load and explore the cars data that is pre-installed\n",
    "in R. Specifically, this tutorial covers:\n",
    "\n",
    "1. Loading data in memory\n",
    "1. Creating SQLContext\n",
    "1. Creating Spark DataFrame\n",
    "1. Group data by columns \n",
    "1. Operating on columns\n",
    "1. Running SQL Queries from a Spark DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in a DataFrame\n",
    "To create a Spark DataFrame we load a local R DataFrame. We use a built-in DataFrame in R for our tutorials. Here is a built-in DataFrame in R, called `mtcars`. This DataFrame includes 32 observations on 11 variables.\n",
    "\n",
    "[, 1]\tmpg\tMiles/(US) --> gallon  \n",
    "[, 2]\tcyl\t--> Number of cylinders  \n",
    "[, 3]\tdisp\t--> Displacement (cu.in.)  \n",
    "[, 4]\thp -->\tGross horsepower  \n",
    "[, 5]\tdrat -->\tRear axle ratio  \n",
    "[, 6]\twt -->\tWeight (lb/1000)  \n",
    "[, 7]\tqsec -->\t1/4 mile time  \n",
    "[, 8]\tvs -->\tV/S  \n",
    "[, 9]\tam -->\tTransmission (0 = automatic, 1 = manual)  \n",
    "[,10]\tgear -->\tNumber of forward gears  \n",
    "[,11]\tcarb -->\tNumber of carburetors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\n",
       "Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n",
       "Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n",
       "Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n",
       "Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n",
       "Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n",
       "Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize SQLContext\n",
    "To work with dataframes we need a SQLContext which is created using `sparkRSQL.init(sc)`. SQLContext uses SparkContext which has been already created, named `sc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext <- sparkRSQL.init(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Spark DataFrames\n",
    "With SQLContext and a loaded local DataFrame, we create a Spark DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cyl: double (nullable = true)\n",
      " |-- disp: double (nullable = true)\n",
      " |-- hp: double (nullable = true)\n",
      " |-- drat: double (nullable = true)\n",
      " |-- wt: double (nullable = true)\n",
      " |-- qsec: double (nullable = true)\n",
      " |-- vs: double (nullable = true)\n",
      " |-- am: double (nullable = true)\n",
      " |-- gear: double (nullable = true)\n",
      " |-- carb: double (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "sdf <- createDataFrame(sqlContext, mtcars) \n",
    "printSchema(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displays the content of the DataFrame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mpg cyl disp  hp drat    wt  qsec vs am gear carb\n",
       "1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n",
       "2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n",
       "3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n",
       "4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n",
       "5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n",
       "6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkR::head(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mpg\n",
       "1 21.0\n",
       "2 21.0\n",
       "3 22.8\n",
       "4 21.4\n",
       "5 18.7\n",
       "6 18.1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkR::head(select(sdf, sdf$mpg ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "Filter the DataFrame to only retain rows with `mpg` less than 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mpg cyl  disp  hp drat   wt  qsec vs am gear carb\n",
       "1 14.3   8 360.0 245 3.21 3.57 15.84  0  0    3    4\n",
       "2 17.8   6 167.6 123 3.92 3.44 18.90  1  0    4    4\n",
       "3 16.4   8 275.8 180 3.07 4.07 17.40  0  0    3    3\n",
       "4 17.3   8 275.8 180 3.07 3.73 17.60  0  0    3    3\n",
       "5 15.2   8 275.8 180 3.07 3.78 18.00  0  0    3    3\n",
       "6 10.4   8 472.0 205 2.93 5.25 17.98  0  0    3    4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkR::head(SparkR::filter(sdf, sdf$mpg < 18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on Columns\n",
    "SparkR also provides a number of functions that can directly applied to columns for data processing and aggregation. The example below shows the use of basic arithmetic functions to convert lb to metric ton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mpg cyl disp  hp drat    wt  qsec vs am gear carb   wtTon\n",
       "1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 1.17900\n",
       "2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 1.29375\n",
       "3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 1.04400\n",
       "4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 1.44675\n",
       "5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 1.54800\n",
       "6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 1.55700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf$wtTon <- sdf$wt * 0.45\n",
    "SparkR::head(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping, Aggregation\n",
    "SparkR data frames support a number of commonly used functions to aggregate data after grouping. For example we can compute the average weight of cars by their cylinders as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  cyl    wtavg\n",
       "1   6 1.402714\n",
       "2   8 1.799646\n",
       "3   4 1.028577"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkR::head(summarize(groupBy(sdf, sdf$cyl), wtavg = avg(sdf$wtTon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  cyl count\n",
       "1   8    14\n",
       "2   4    11\n",
       "3   6     7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also sort the output from the aggregation to get the most common cars\n",
    "car_counts <-summarize(groupBy(sdf, sdf$cyl), count = n(sdf$wtTon))\n",
    "SparkR::head(arrange(car_counts, desc(car_counts$count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running SQL Queries from Spark DataFrames\n",
    "A Spark DataFrame can also be registered as a temporary table in Spark SQL and registering a DataFrame as a table allows you to run SQL queries over its data. The `sql` function enables applications to run SQL queries programmatically and returns the result as a DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  gear\n",
       "1    4\n",
       "2    4\n",
       "3    4\n",
       "4    3\n",
       "5    3\n",
       "6    3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register this DataFrame as a table.\n",
    "registerTempTable(sdf, \"cars\")\n",
    "# SQL statements can be run by using the sql method\n",
    "highgearcars <- sql(sqlContext, \"SELECT gear FROM cars WHERE cyl >= 4 AND cyl <= 9\")\n",
    "SparkR::head(highgearcars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NOTE: This tutorial draws heavily from the original \n",
    "[Spark Quick Start Guide](http://spark.apache.org/docs/latest/quick-start.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free courses on [Big Data University](https://bigdatauniversity.com/courses/analyzing-big-data-r-using-apache-spark/?utm_source=tutorial-spark-r&utm_medium=dswb&utm_campaign=bdu):\n",
    "\n",
    "<a href=\"https://bigdatauniversity.com/courses/analyzing-big-data-r-using-apache-spark/?utm_source=tutorial-spark-r&utm_medium=dswb&utm_campaign=bdu\"><img src = \"https://ibm.box.com/shared/static/14f58d6iazn71i794oqsdlaimp9k51xq.png\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Authors:</h3>\n",
    "<br>\n",
    "<a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">\n",
    "    <div class=\"teacher-image\" style=\"    float: left;\n",
    "        width: 115px;\n",
    "        height: 115px;\n",
    "        margin-right: 10px;\n",
    "        margin-bottom: 10px;\n",
    "        border: 1px solid #CCC;\n",
    "        padding: 3px;\n",
    "        border-radius: 3px;\n",
    "        text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\"/>\n",
    "    </div>\n",
    "</a>\n",
    "\n",
    "<h4>Saeed Aghabozorgi</h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<a href=\"https://ca.linkedin.com/in/polonglin\">\n",
    "    <div class=\"teacher-image\" style=\"    float: left;\n",
    "        width: 115px;\n",
    "        height: 115px;\n",
    "        margin-right: 10px;\n",
    "        margin-bottom: 10px;\n",
    "        border: 1px solid #CCC;\n",
    "        padding: 3px;\n",
    "        border-radius: 3px;\n",
    "        text-align: center;\"><img class=\"alignnone size-medium wp-image-2177\" src=\"https://ibm.box.com/shared/static/2ygdi03ahcr97df2ofrr6cf8knq4kodd.jpg\" alt=\"Polong Lin\" width=\"300\" height=\"300\"/>\n",
    "    </div>\n",
    "</a>\n",
    "<h4>Polong Lin</h4>\n",
    "<p>\n",
    "<a href=\"https://ca.linkedin.com/in/polonglin\">Polong Lin</a> is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds a M.Sc. in Cognitive Psychology.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

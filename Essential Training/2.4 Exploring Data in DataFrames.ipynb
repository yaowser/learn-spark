{"cells":[{"cell_type":"code","source":["%fs ls /databricks-datasets/online_retail/data-001/"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# specify path\npath = \"/databricks-datasets/online_retail/data-001/data.csv\"\n\n# read in file using csv format\ndf = spark.read.load(path,\n                    format='com.databricks.spark.csv', \n                    header='true',\n                    inferSchema='true')\n\n# show 20 rows\ndisplay(df)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# take a look at our schema\ndf.printSchema()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# show just the countries\ndf.select(\"Country\").show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# For this we'll need a few functions\ndisplay( # shows the results in a grid\n   df \n    .select(\"Country\") # chooses just the 1 column\n    .distinct() # removes duplicates\n    .orderBy(\"Country\") # sorts results in ascending\n)\n        "],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["display(\n  df\n    .select(df[\"InvoiceNo\"],df[\"UnitPrice\"]*df[\"Quantity\"])\n    .groupBy(\"InvoiceNo\")\n    .sum()\n  )"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["df.filter(df[\"InvoiceNo\"]==536596).show()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(\n  df\n    .select(df[\"Country\"], df[\"Description\"],(df[\"UnitPrice\"]*df[\"Quantity\"]).alias(\"Total\"))\n    .groupBy(\"Country\", \"Description\")\n    .sum()\n    .filter(df[\"Country\"]==\"United Kingdom\")\n    .sort(\"sum(Total)\", ascending=False)\n    .limit(10)\n  )"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"2.4 Exploring Data in DataFrames","notebookId":2279204284361382},"nbformat":4,"nbformat_minor":0}

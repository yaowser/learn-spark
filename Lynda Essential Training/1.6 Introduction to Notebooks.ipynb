{"cells":[{"cell_type":"markdown","source":["## Markdown Content \nYou can add lists like so\n- item 1\n- item 2\n  - sub-item 1\n  \nI often create links also like this\n[My Site](http://bensullins.com)\n[Another Site](http://databricks.com)\n\nMore Markdown can be found [here](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)"],"metadata":{}},{"cell_type":"code","source":["# Now let's create a simple list with 10000 integers\n# xrange() is more memory efficient so let's use that\n\ndata = xrange(1, 10001)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# now see how big our list is\nlen(data)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# So far we've done just basic Python, now let's use Spark\n# Start by using 'sc' to tell Spark we want to use the SparkContext\n# Then we use parallelize() to create a Dataset and spread it across\n# the cluster partitions\n\nds = sc.parallelize(data, 8)\n# more info on parallelize here \n# help(sc.parallelize)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# show what we have in ds using the collect() action\nprint ds.collect() # we don't need to use \"print\" here, but it's better for formatting"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":6}],"metadata":{"name":"1.6 Introduction to Notebooks","notebookId":2279204284361485},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"code","source":["%sh curl -O 'https://raw.githubusercontent.com/bsullins/bensullins.com-freebies/master/CogsleyServices-SalesData-US.csv'\n# saves file to file:/databricks/driver/CogsleyServices-SalesData-US.csv"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["path = 'file:/databricks/driver/CogsleyServices-SalesData-US.csv'\n# path = \"/databricks-datasets/samples/population-vs-price/data_geo.csv\"\n\n# Use the Spark CSV datasource with options specifying:\n# - First line of file is a header\n# - Automatically infer the schema of the data\ndata = sqlContext.read.format(\"csv\")\\\n  .option(\"header\", \"true\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(path)\n \ndata.cache() # Cache data for faster reuse\ndata = data.dropna() # drop rows with missing values\n \n# Register table so it is accessible via SQL Context\n# For Apache Spark = 2.0\n# data.createOrReplaceTempView(\"data_geo\")\n\ndisplay(data)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Get monthly sales totals\nsummary = data.select(\"OrderMonthYear\", \"SaleAmount\").groupBy(\"OrderMonthYear\").sum().orderBy(\"OrderMonthYear\").toDF(\"OrderMonthYear\",\"SaleAmount\")\n\n# Convert OrderMonthYear to integer type\nresults = summary.map(lambda r: (int(r.OrderMonthYear.replace('-','')), r.SaleAmount)).toDF([\"OrderMonthYear\",\"SaleAmount\"])\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# convenience for specifying schema\nfrom pyspark.mllib.regression import LabeledPoint\n \ndata = results.select(\"OrderMonthYear\", \"SaleAmount\")\\\n  .map(lambda r: LabeledPoint(r[1], [r[0]]))\\\n  .toDF()\n  \ndisplay(data)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"4.2 Preparing Data for Machine Learning","notebookId":2279204284361409},"nbformat":4,"nbformat_minor":0}
